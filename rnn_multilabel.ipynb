{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_multilabel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizkyfalih/Hadist-Multilabel/blob/master/rnn_multilabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9twKZcKWqZmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hadist Multilabel RNN"
      ]
    },
    {
      "metadata": {
        "id": "zcx-vv1yOAah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "metadata": {
        "id": "nfpFCE9eLzaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81d8a903-f6a8-43be-8eaf-ccd9170f326a"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, GRU,SimpleRNN\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BEobXoCysk3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_label(Y):\n",
        "  Y1 = []\n",
        "  Y2 = []\n",
        "  Y3 = []\n",
        "\n",
        "  for i in range(len(Y)):\n",
        "    for j in range(len(Y[i])):\n",
        "      if j == 0:\n",
        "        Y1.append(Y[i][j])\n",
        "      elif j == 1:\n",
        "        Y2.append(Y[i][j])\n",
        "      elif j == 2:\n",
        "        Y3.append(Y[i][j])\n",
        "\n",
        "  Y1 = np.array(Y1).reshape([-1,1])\n",
        "  Y2 = np.array(Y2).reshape([-1,1])\n",
        "  Y3 = np.array(Y3).reshape([-1,1])\n",
        "\n",
        "  return Y1, Y2, Y3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82qVDgbtsYru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Processing the data"
      ]
    },
    {
      "metadata": {
        "id": "C32ZQzpcObXE",
        "colab_type": "code",
        "outputId": "eda319dc-95d8-4b5c-c5b8-2189f87939a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "df = pd.read_excel('Multilabel Clean.xlsx')\n",
        "df[:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Anjuran</th>\n",
              "      <th>Larangan</th>\n",
              "      <th>Informasi</th>\n",
              "      <th>Bab Kitab</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Len Words</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Semua perbuatan tergantung niatnya, dan (balas...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>732.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Terkadang datang kepadaku seperti suara gemeri...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bacalah? Beliau menjawab: Aku tidak bisa baca....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>426</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sangat kuat keinginannya untuk menghafalkan ap...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>157</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>manusia yang paling lembut terutama pada bulan...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dari Muhammad, hamba Allah dan Rasul-Nya untuk...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>559</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Islam dibangun diatas lima (landasan); persaks...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Iman memiliki lebih dari enam puluh cabang, da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Seorang muslim adalah orang yang Kaum Muslimin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Siapa yang Kaum Muslimin selamat dari lisan da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Data  Anjuran  Larangan  \\\n",
              "0  Semua perbuatan tergantung niatnya, dan (balas...        0         0   \n",
              "1  Terkadang datang kepadaku seperti suara gemeri...        0         0   \n",
              "2  Bacalah? Beliau menjawab: Aku tidak bisa baca....        0         0   \n",
              "3  sangat kuat keinginannya untuk menghafalkan ap...        0         1   \n",
              "4  manusia yang paling lembut terutama pada bulan...        0         0   \n",
              "5  Dari Muhammad, hamba Allah dan Rasul-Nya untuk...        1         1   \n",
              "6  Islam dibangun diatas lima (landasan); persaks...        0         0   \n",
              "7  Iman memiliki lebih dari enam puluh cabang, da...        0         0   \n",
              "8  Seorang muslim adalah orang yang Kaum Muslimin...        0         1   \n",
              "9  Siapa yang Kaum Muslimin selamat dari lisan da...        0         0   \n",
              "\n",
              "   Informasi  Bab Kitab  Unnamed: 5  Len Words  Unnamed: 7    Max  \n",
              "0          1          1         NaN         35         NaN  732.0  \n",
              "1          1          1         NaN         64         NaN    NaN  \n",
              "2          1          1         NaN        426         NaN    NaN  \n",
              "3          1          1         NaN        157         NaN    NaN  \n",
              "4          1          1         NaN         41         NaN    NaN  \n",
              "5          1          1         NaN        559         NaN    NaN  \n",
              "6          1          2         NaN         24         NaN    NaN  \n",
              "7          1          2         NaN         13         NaN    NaN  \n",
              "8          1          2         NaN         64         NaN    NaN  \n",
              "9          1          2         NaN          9         NaN    NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "1xmTFY52VOqW",
        "colab_type": "code",
        "outputId": "0d676496-a7a0-4e42-f3ee-36451eb336ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1059 entries, 0 to 1058\n",
            "Data columns (total 9 columns):\n",
            "Data          1059 non-null object\n",
            "Anjuran       1059 non-null int64\n",
            "Larangan      1059 non-null int64\n",
            "Informasi     1059 non-null int64\n",
            "Bab Kitab     1059 non-null int64\n",
            "Unnamed: 5    0 non-null float64\n",
            "Len Words     1059 non-null int64\n",
            "Unnamed: 7    0 non-null float64\n",
            "Max           1 non-null float64\n",
            "dtypes: float64(3), int64(5), object(1)\n",
            "memory usage: 74.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jMtNxA0wXcTV",
        "colab_type": "code",
        "outputId": "db72bb29-fd29-4592-fc81-f9f3147bc8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "sns.countplot(df.Larangan)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Number of false and true anjuran information')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of false and true anjuran information')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEVCAYAAAD6u3K7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mmuc12QMs2MX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize the data\n"
      ]
    },
    {
      "metadata": {
        "id": "n-lZJ6pgU5M9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df.Data\n",
        "Y1 = df.Anjuran\n",
        "Y2 = df.Larangan\n",
        "Y3 = df.Informasi\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Y1 = le.fit_transform(Y1)\n",
        "# Y1 = Y1.reshape(-1,1)\n",
        "Y1 = Y1.values.reshape([-1,1])\n",
        "\n",
        "# Y2 = le.fit_transform(Y2)\n",
        "# Y2 = Y2.reshape(-1,1)\n",
        "Y2 = Y2.values.reshape([-1,1])\n",
        "\n",
        "# Y3 = le.fit_transform(Y3)\n",
        "# Y3 = Y3.reshape(-1,1)\n",
        "Y3 = Y3.values.reshape([-1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DhFFEnIu8cFJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(Y1),3))\n",
        "for i in range(len(Y)):\n",
        "  for j in range(len(Y[i])):\n",
        "    if j == 0:\n",
        "      Y[i][j] = Y1[i]\n",
        "    elif j == 1:\n",
        "      Y[i][j] = Y2[i]\n",
        "    elif j == 2:\n",
        "      Y[i][j] = Y3[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "92ddf398-f873-470b-8f00-5520da55f189",
        "id": "lAm8oS4M8b0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1059, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "c78cz19btFvA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split the data"
      ]
    },
    {
      "metadata": {
        "id": "mfmXdnFZpYuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.20, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "THkAgTqjqQVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y1_train,Y2_train,Y3_train = extract_label(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYH5mfxItAMw",
        "colab_type": "code",
        "outputId": "7224efb9-c69a-46c8-cc99-0a685b6a7864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(847,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "MmI4Kdn0uXAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y1_test,Y2_test,Y3_test = extract_label(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yyg9N4_nwaRO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "hNi_qeqSz1TO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Without preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "3xNUHPOnatMg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 155\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len, truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UnGW77a0PLAp",
        "colab_type": "code",
        "outputId": "4596ba7c-74f2-4971-b896-17330e805a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test1\n",
        "max_words = 1000\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "\n",
        "#count max token\n",
        "num_tokens = np.array([len(tokens) for tokens in sequences])\n",
        "max_len = int(np.mean(num_tokens) + 2 * np.std(num_tokens))\n",
        "max_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "zalJCotzPJlh",
        "colab_type": "code",
        "outputId": "12c42c89-e026-4127-9445-ab2118fc7f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.sum(num_tokens < max_len) / len(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9716646989374262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "a-MWAHZw1K8a",
        "colab_type": "code",
        "outputId": "a186087b-bbcd-4758-c3d3-dfe2353a610a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "sequences_matrix[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([342,  30,  82,  23, 182,   3,  65,   7,   7,  10, 322,  15,   5,\n",
              "        60,  30, 831,  38,   7,   2, 603,   1, 832, 375,  53, 102,  39,\n",
              "       496,  22,  12,  26, 604, 671, 274, 227,  23, 182,   7,   7,   3,\n",
              "         5,  81,   1,  20,  66, 115, 605,   2, 439, 196,  16, 440,  40,\n",
              "       113,  61, 473,   5,  57,  93,  17,  28,  45, 174, 174, 606,  30,\n",
              "       831, 183, 182,   3,   8,  30, 831, 182,   3, 413,   5,  14, 741,\n",
              "       441, 161,   5,  94,  32, 110,  13,  68,  37,   7, 497,   4,  85,\n",
              "       245,   5, 190,  52, 672,  50,   5,  30,  82,  23, 673, 111,  21,\n",
              "       228, 236,  77,  74,  13, 296, 183,  31, 442,  27,  14,   5,  11,\n",
              "        11, 268,  30,  82, 322,  15,  39, 498,  90,   5,   3,  14,  30,\n",
              "        82,   3, 237, 175,   5,   1,   7,   7,   3,  13, 237, 175,  30,\n",
              "        82,  10,  39, 498,  44,  13, 145,  30, 742,  66,   6, 306],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "7E5ubKI8zQP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build RNN"
      ]
    },
    {
      "metadata": {
        "id": "t2-1seafVQlG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "def testRNN():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_words, 64))\n",
        "    model.add(SimpleRNN(64, init='uniform', dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, init='uniform', activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "#     inputs = Input(name='inputs',shape=[max_len])\n",
        "#     layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "#     layer = GRU(64)(layer)\n",
        "#     layer = Dense(256,name='FC1')(layer)\n",
        "#     layer = Activation('relu')(layer)\n",
        "#     layer = Dropout(0.5)(layer)\n",
        "#     layer = Dense(1,name='out_layer')(layer)\n",
        "#     layer = Activation('sigmoid')(layer)\n",
        "#     model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTM-fQKbexrO",
        "colab_type": "code",
        "outputId": "8da813fc-4556-40ca-e2ec-7af4d1e48078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "model = testRNN()\n",
        "model.summary()\n",
        "# model1.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_13 (SimpleRNN)    (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 80,963\n",
            "Trainable params: 80,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uyuk38AbseKP"
      },
      "cell_type": "markdown",
      "source": [
        "### Simple RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qIqVrtOMseKU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "def simpleRNN():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_words, 64))\n",
        "    model.add(SimpleRNN(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "#     inputs = Input(name='inputs',shape=[max_len])\n",
        "#     layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "#     layer = GRU(64)(layer)\n",
        "#     layer = Dense(256,name='FC1')(layer)\n",
        "#     layer = Activation('relu')(layer)\n",
        "#     layer = Dropout(0.5)(layer)\n",
        "#     layer = Dense(1,name='out_layer')(layer)\n",
        "#     layer = Activation('sigmoid')(layer)\n",
        "#     model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "94e8c0fe-40d2-49d0-f895-245921fbd3a7",
        "id": "6lEfmDzyseKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "modelSimple1 = simpleRNN()\n",
        "modelSimple1.summary()\n",
        "# model1.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 72,321\n",
            "Trainable params: 72,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c6c0c99d-253d-4f56-c7df-254e3ba8d08e",
        "id": "OX4hRPbvseKv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelSimple2 = simpleRNN()\n",
        "modelSimple2.summary()\n",
        "# model2.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 72,321\n",
            "Trainable params: 72,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8eedfe0b-7666-41d5-824f-ee09510f3a7e",
        "id": "B-S7231mseK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelSimple3 = simpleRNN()\n",
        "modelSimple3.summary()\n",
        "# model3.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 72,321\n",
            "Trainable params: 72,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fHyvqK57sE2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM RNN"
      ]
    },
    {
      "metadata": {
        "id": "zhxiHKIwazKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "def lstmRNN():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_words, 64))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "#     inputs = Input(name='inputs',shape=[max_len])\n",
        "#     layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "#     layer = GRU(64)(layer)\n",
        "#     layer = Dense(256,name='FC1')(layer)\n",
        "#     layer = Activation('relu')(layer)\n",
        "#     layer = Dropout(0.5)(layer)\n",
        "#     layer = Dense(1,name='out_layer')(layer)\n",
        "#     layer = Activation('sigmoid')(layer)\n",
        "#     model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwmVOb0-a2Nw",
        "colab_type": "code",
        "outputId": "ef096af1-d433-4bbd-c350-bf794b8cd91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM1 = lstmRNN()\n",
        "modelLSTM1.summary()\n",
        "# model1.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 97,089\n",
            "Trainable params: 97,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qW4Fwt5S0cav",
        "colab_type": "code",
        "outputId": "e34cb2a7-3a40-4ace-9a76-54e5d3cb1ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM2 = lstmRNN()\n",
        "modelLSTM2.summary()\n",
        "# model2.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 97,089\n",
            "Trainable params: 97,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7i8OLL40fqm",
        "colab_type": "code",
        "outputId": "4f610ee9-9c9c-4409-8c44-934a9889da2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM3 = lstmRNN()\n",
        "modelLSTM3.summary()\n",
        "# model3.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 97,089\n",
            "Trainable params: 97,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eBGtsIZCshtK"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CxrHeHh4shtQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "def gruRNN():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_words, 64))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "#     inputs = Input(name='inputs',shape=[max_len])\n",
        "#     layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "#     layer = GRU(64)(layer)\n",
        "#     layer = Dense(256,name='FC1')(layer)\n",
        "#     layer = Activation('relu')(layer)\n",
        "#     layer = Dropout(0.5)(layer)\n",
        "#     layer = Dense(1,name='out_layer')(layer)\n",
        "#     layer = Activation('sigmoid')(layer)\n",
        "#     model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e9b4d1c7-0465-46b2-dcd7-b2511038e184",
        "id": "s3eC3Hw0shtd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU1 = gruRNN()\n",
        "modelGRU1.summary()\n",
        "# model1.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                24768     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 88,833\n",
            "Trainable params: 88,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4bb3fcac-bc65-4230-dbb7-871fd84d60c8",
        "id": "yUAGakd4shtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU2 = gruRNN()\n",
        "modelGRU2.summary()\n",
        "# model2.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 64)                24768     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 88,833\n",
            "Trainable params: 88,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "83049962-8944-4bb6-84b0-cde47904110f",
        "id": "K4Y8vwihshuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU3 = gruRNN()\n",
        "modelGRU3.summary()\n",
        "# model3.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 64)                24768     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 88,833\n",
            "Trainable params: 88,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VhL1NLrx1VXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ]
    },
    {
      "metadata": {
        "id": "atzPgWvScTsR",
        "colab_type": "code",
        "outputId": "dee6cadc-95b4-4e80-9c29-292ebb634da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix1,Y_Train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-963f6e54be51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(sequences_matrix1,Y_Train,batch_size=128,epochs=10,\n\u001b[0m\u001b[1;32m      2\u001b[0m           validation_split=0.2)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MJIfgIcKvIYh"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the data with Simple RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8335dda0-b381-4284-e490-9364252a433e",
        "id": "oZGGV9cqvIYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "cell_type": "code",
      "source": [
        "history1 = modelSimple1.fit(sequences_matrix,Y1_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 3s 5ms/step - loss: 0.5815 - acc: 0.7282 - val_loss: 0.4937 - val_acc: 0.8059\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 0s 412us/step - loss: 0.5042 - acc: 0.7784 - val_loss: 0.4938 - val_acc: 0.8059\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 0s 425us/step - loss: 0.4541 - acc: 0.8035 - val_loss: 0.5221 - val_acc: 0.7824\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 0s 410us/step - loss: 0.3773 - acc: 0.8419 - val_loss: 0.5587 - val_acc: 0.7588\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 0s 399us/step - loss: 0.4409 - acc: 0.7386 - val_loss: 0.5065 - val_acc: 0.8118\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 0s 410us/step - loss: 0.3256 - acc: 0.8582 - val_loss: 0.5035 - val_acc: 0.8059\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 0s 412us/step - loss: 0.2517 - acc: 0.9321 - val_loss: 0.4958 - val_acc: 0.8059\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 0s 406us/step - loss: 0.2030 - acc: 0.9586 - val_loss: 0.5065 - val_acc: 0.8176\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 0s 406us/step - loss: 0.1711 - acc: 0.9705 - val_loss: 0.5388 - val_acc: 0.7529\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 0s 420us/step - loss: 0.1447 - acc: 0.9793 - val_loss: 0.5404 - val_acc: 0.7412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EWdiOHLu_crn",
        "colab_type": "code",
        "outputId": "79a5dce3-446e-406e-9099-cb318e2283da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "pyplot.plot(history1.history['loss'])\n",
        "pyplot.plot(history1.history['val_loss'])\n",
        "pyplot.title('model train vs validation loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8e43052c-094e-4330-f518-d4988c093b78",
        "id": "me3F8MAyvIYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelSimple2.fit(sequences_matrix,Y2_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 1s 807us/step - loss: 0.4458 - acc: 0.8508 - val_loss: 0.3253 - val_acc: 0.9118\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 0s 413us/step - loss: 0.3390 - acc: 0.8892 - val_loss: 0.3046 - val_acc: 0.9118\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 0s 415us/step - loss: 0.3411 - acc: 0.8789 - val_loss: 0.3130 - val_acc: 0.9118\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 0s 415us/step - loss: 0.3124 - acc: 0.8892 - val_loss: 0.3311 - val_acc: 0.9118\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 0s 403us/step - loss: 0.2836 - acc: 0.8892 - val_loss: 0.3038 - val_acc: 0.9118\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 0s 412us/step - loss: 0.2422 - acc: 0.9084 - val_loss: 0.4358 - val_acc: 0.9000\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 0s 418us/step - loss: 0.2420 - acc: 0.9261 - val_loss: 0.3054 - val_acc: 0.9118\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 0s 408us/step - loss: 0.1702 - acc: 0.9439 - val_loss: 0.3176 - val_acc: 0.9118\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 0s 402us/step - loss: 0.1317 - acc: 0.9823 - val_loss: 0.2964 - val_acc: 0.9118\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 0s 402us/step - loss: 0.1160 - acc: 0.9719 - val_loss: 0.2927 - val_acc: 0.9118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa523e620f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2b1ee771-82c5-483d-ce3d-1dd06887ee0d",
        "id": "nB4JOFUivIYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelSimple3.fit(sequences_matrix,Y3_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 1s 871us/step - loss: 0.5737 - acc: 0.7223 - val_loss: 0.5147 - val_acc: 0.9471\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 0s 406us/step - loss: 0.3448 - acc: 0.9778 - val_loss: 0.4294 - val_acc: 0.9882\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 0s 404us/step - loss: 0.2574 - acc: 0.9778 - val_loss: 0.1737 - val_acc: 0.9882\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 0s 415us/step - loss: 0.1632 - acc: 0.9778 - val_loss: 0.1267 - val_acc: 0.9882\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 0s 421us/step - loss: 0.1316 - acc: 0.9778 - val_loss: 0.1027 - val_acc: 0.9882\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 0s 404us/step - loss: 0.1157 - acc: 0.9778 - val_loss: 0.0875 - val_acc: 0.9882\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 0s 407us/step - loss: 0.1063 - acc: 0.9778 - val_loss: 0.0802 - val_acc: 0.9882\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 0s 414us/step - loss: 0.1011 - acc: 0.9778 - val_loss: 0.0733 - val_acc: 0.9882\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 0s 401us/step - loss: 0.0979 - acc: 0.9778 - val_loss: 0.0703 - val_acc: 0.9882\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 0s 410us/step - loss: 0.0950 - acc: 0.9778 - val_loss: 0.0690 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa51616df28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "jIFGYYLyBG44",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Save The Models"
      ]
    },
    {
      "metadata": {
        "id": "uyxOfhtiBRyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelSimple1.save('modelSimple1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwPfxmDkBUz_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelSimple2.save('modelSimple2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5b38219NBU_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelSimple3.save('modelSimple3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STnWnNMAz5Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the data with LSTM RNN"
      ]
    },
    {
      "metadata": {
        "id": "EniIroPva5UV",
        "colab_type": "code",
        "outputId": "724419a2-fb08-49ee-a2e3-80eb9dc1b509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM1.fit(sequences_matrix,Y1_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6542 - acc: 0.7238 - val_loss: 0.6312 - val_acc: 0.8059\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.5531 - acc: 0.7784 - val_loss: 0.4818 - val_acc: 0.8059\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.4992 - acc: 0.7784 - val_loss: 0.4717 - val_acc: 0.8059\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.4537 - acc: 0.7799 - val_loss: 0.4691 - val_acc: 0.8059\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.4310 - acc: 0.7932 - val_loss: 0.4806 - val_acc: 0.8294\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3890 - acc: 0.8257 - val_loss: 0.4555 - val_acc: 0.8294\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3598 - acc: 0.8479 - val_loss: 0.4442 - val_acc: 0.8294\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3076 - acc: 0.8774 - val_loss: 0.4576 - val_acc: 0.8294\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.2857 - acc: 0.8833 - val_loss: 0.4306 - val_acc: 0.8176\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.2326 - acc: 0.9188 - val_loss: 0.4489 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa510d6f828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "BDwaryPn0_EO",
        "colab_type": "code",
        "outputId": "83d7e5c8-02ee-433b-aaaf-bc447274ab38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM2.fit(sequences_matrix,Y2_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6309 - acc: 0.8139 - val_loss: 0.3451 - val_acc: 0.9118\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3601 - acc: 0.8892 - val_loss: 0.3338 - val_acc: 0.9118\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3513 - acc: 0.8892 - val_loss: 0.2976 - val_acc: 0.9118\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.3075 - acc: 0.8892 - val_loss: 0.2947 - val_acc: 0.9118\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.2737 - acc: 0.8922 - val_loss: 0.2974 - val_acc: 0.9118\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.2293 - acc: 0.8996 - val_loss: 0.3031 - val_acc: 0.9118\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.2157 - acc: 0.9173 - val_loss: 0.2962 - val_acc: 0.9118\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1735 - acc: 0.9261 - val_loss: 0.2958 - val_acc: 0.9118\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1413 - acc: 0.9365 - val_loss: 0.3432 - val_acc: 0.9118\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1244 - acc: 0.9527 - val_loss: 0.3530 - val_acc: 0.9118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa510406dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "6PPg4-a11KPR",
        "colab_type": "code",
        "outputId": "5fc4c67e-e27a-4bf7-fc5c-15520b6b65b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelLSTM3.fit(sequences_matrix,Y3_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6048 - acc: 0.8981 - val_loss: 0.0645 - val_acc: 0.9882\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1072 - acc: 0.9778 - val_loss: 0.0835 - val_acc: 0.9882\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1083 - acc: 0.9778 - val_loss: 0.0707 - val_acc: 0.9882\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1067 - acc: 0.9778 - val_loss: 0.0771 - val_acc: 0.9882\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1079 - acc: 0.9778 - val_loss: 0.0690 - val_acc: 0.9882\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1028 - acc: 0.9778 - val_loss: 0.0683 - val_acc: 0.9882\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1034 - acc: 0.9778 - val_loss: 0.0681 - val_acc: 0.9882\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.1042 - acc: 0.9778 - val_loss: 0.0645 - val_acc: 0.9882\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.0942 - acc: 0.9778 - val_loss: 0.0853 - val_acc: 0.9882\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 2ms/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0583 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4e9aa3a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "f_Qu-zl1B029"
      },
      "cell_type": "markdown",
      "source": [
        "#### Save The Models"
      ]
    },
    {
      "metadata": {
        "id": "BN90MT4bB32e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelLSTM1.save('modelLSTM1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbUIbY2vB-Q5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelLSTM2.save('modelLSTM2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSO38Yr8CDcc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelLSTM3.save('modelLSTM3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "x-UCczAxvKPF"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the data with GRU RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0c59b8b9-4332-40ee-84b2-fbb7bca1fcbc",
        "id": "AK2WDNd_vKPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU1.fit(sequences_matrix,Y1_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6650 - acc: 0.7238 - val_loss: 0.5893 - val_acc: 0.8059\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.5281 - acc: 0.7784 - val_loss: 0.4739 - val_acc: 0.8059\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.4563 - acc: 0.7784 - val_loss: 0.4772 - val_acc: 0.8118\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.4122 - acc: 0.7917 - val_loss: 0.4559 - val_acc: 0.8176\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.3641 - acc: 0.8109 - val_loss: 0.4566 - val_acc: 0.8176\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.3169 - acc: 0.8464 - val_loss: 0.5061 - val_acc: 0.8176\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2763 - acc: 0.8715 - val_loss: 0.4575 - val_acc: 0.8059\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2625 - acc: 0.9010 - val_loss: 0.4429 - val_acc: 0.7824\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2028 - acc: 0.9291 - val_loss: 0.4544 - val_acc: 0.8000\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1669 - acc: 0.9365 - val_loss: 0.4652 - val_acc: 0.7941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4e8a41e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "16e26d9f-b32d-4b4b-fd0a-da3614e546be",
        "id": "Y1-sq9uFvKPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU2.fit(sequences_matrix,Y2_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6498 - acc: 0.7962 - val_loss: 0.5249 - val_acc: 0.9118\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.4226 - acc: 0.8892 - val_loss: 0.3495 - val_acc: 0.9118\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.3184 - acc: 0.8892 - val_loss: 0.2799 - val_acc: 0.9118\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2713 - acc: 0.8892 - val_loss: 0.2815 - val_acc: 0.9118\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2474 - acc: 0.8907 - val_loss: 0.2842 - val_acc: 0.9118\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2129 - acc: 0.8966 - val_loss: 0.3301 - val_acc: 0.9118\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1942 - acc: 0.9055 - val_loss: 0.3154 - val_acc: 0.9118\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1551 - acc: 0.9247 - val_loss: 0.3129 - val_acc: 0.9118\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1502 - acc: 0.9380 - val_loss: 0.3171 - val_acc: 0.9118\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1046 - acc: 0.9498 - val_loss: 0.3324 - val_acc: 0.9118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4e82fe3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "00846c2b-51ff-4bbf-9b4d-838115e7628a",
        "id": "nZm1BtfevKPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "modelGRU3.fit(sequences_matrix,Y3_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 677 samples, validate on 170 samples\n",
            "Epoch 1/10\n",
            "677/677 [==============================] - 2s 3ms/step - loss: 0.6310 - acc: 0.8641 - val_loss: 0.4671 - val_acc: 0.9882\n",
            "Epoch 2/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.2851 - acc: 0.9778 - val_loss: 0.0631 - val_acc: 0.9882\n",
            "Epoch 3/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.1112 - acc: 0.9778 - val_loss: 0.0574 - val_acc: 0.9882\n",
            "Epoch 4/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0950 - acc: 0.9778 - val_loss: 0.0538 - val_acc: 0.9882\n",
            "Epoch 5/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0824 - acc: 0.9778 - val_loss: 0.0528 - val_acc: 0.9882\n",
            "Epoch 6/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0775 - acc: 0.9778 - val_loss: 0.0498 - val_acc: 0.9882\n",
            "Epoch 7/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0709 - acc: 0.9778 - val_loss: 0.0481 - val_acc: 0.9882\n",
            "Epoch 8/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0571 - acc: 0.9778 - val_loss: 0.0523 - val_acc: 0.9882\n",
            "Epoch 9/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0481 - acc: 0.9793 - val_loss: 0.0584 - val_acc: 0.9882\n",
            "Epoch 10/10\n",
            "677/677 [==============================] - 1s 1ms/step - loss: 0.0429 - acc: 0.9793 - val_loss: 0.0516 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4e7a857f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "HhXi_Y2HCPi2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Save The Models"
      ]
    },
    {
      "metadata": {
        "id": "d9kKZKdkCO9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelGRU1.save('modelGRU1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_yGDCb-CZQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelGRU2.save('modelGRU2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahKkAxDgCb5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelGRU3.save('modelGRU3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rzSncte1kE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Accuracy Data"
      ]
    },
    {
      "metadata": {
        "id": "t7Ywe0QtheV6",
        "colab_type": "code",
        "outputId": "f43750a0-59bc-4702-ecaf-b4917af06f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X1_test)\n",
        "test_sequences_matrix1 = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-60217721d71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_sequences_matrix1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X1_test' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xNS9k9OAhhkm",
        "colab_type": "code",
        "outputId": "f368ba67-830c-408a-965e-c9e771721689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "cell_type": "code",
      "source": [
        "y_predict = model.predict(test_sequences_matrix1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-79afab27bbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences_matrix1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lS2RsvX3hwBZ",
        "colab_type": "code",
        "outputId": "cce50b4f-a10a-4927-fe6a-e63199a7d003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3578
        }
      },
      "cell_type": "code",
      "source": [
        "y_predict "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19173816, 0.08064577, 0.98373425],\n",
              "       [0.19113412, 0.08042666, 0.98384094],\n",
              "       [0.19050124, 0.079907  , 0.9840975 ],\n",
              "       [0.19038337, 0.08002397, 0.98398995],\n",
              "       [0.19016719, 0.07940093, 0.98420733],\n",
              "       [0.19238919, 0.08168149, 0.98343265],\n",
              "       [0.19068974, 0.08013192, 0.98392594],\n",
              "       [0.190727  , 0.07999209, 0.9839591 ],\n",
              "       [0.1928702 , 0.08139902, 0.9836076 ],\n",
              "       [0.19121426, 0.08062327, 0.98380816],\n",
              "       [0.19061753, 0.08014762, 0.98401654],\n",
              "       [0.19168788, 0.08117095, 0.98362374],\n",
              "       [0.19116676, 0.08072308, 0.98377836],\n",
              "       [0.19251224, 0.08144709, 0.9836021 ],\n",
              "       [0.19085598, 0.08045769, 0.9838407 ],\n",
              "       [0.19193101, 0.08102089, 0.9836587 ],\n",
              "       [0.19170669, 0.0811162 , 0.9836385 ],\n",
              "       [0.19075277, 0.08017609, 0.98399323],\n",
              "       [0.19183126, 0.08110967, 0.9836981 ],\n",
              "       [0.19187477, 0.08108369, 0.98368937],\n",
              "       [0.1905404 , 0.08018908, 0.9840089 ],\n",
              "       [0.19009843, 0.07968938, 0.9841809 ],\n",
              "       [0.19011527, 0.07993773, 0.984087  ],\n",
              "       [0.19153088, 0.08076993, 0.98379314],\n",
              "       [0.19082206, 0.08020601, 0.98396325],\n",
              "       [0.19038615, 0.07974607, 0.9841808 ],\n",
              "       [0.19235644, 0.08152986, 0.9835595 ],\n",
              "       [0.19003597, 0.07972947, 0.98418593],\n",
              "       [0.19168708, 0.0810197 , 0.9836698 ],\n",
              "       [0.19020122, 0.07992485, 0.984129  ],\n",
              "       [0.19050819, 0.07982188, 0.9840598 ],\n",
              "       [0.18971094, 0.07889354, 0.98446435],\n",
              "       [0.1897929 , 0.07901108, 0.9843666 ],\n",
              "       [0.19047078, 0.07991412, 0.98405486],\n",
              "       [0.19106683, 0.08055988, 0.9838145 ],\n",
              "       [0.19013885, 0.07988027, 0.98404217],\n",
              "       [0.18944812, 0.0787361 , 0.9844296 ],\n",
              "       [0.19053209, 0.08000422, 0.9839616 ],\n",
              "       [0.19147435, 0.08099779, 0.98375666],\n",
              "       [0.18916032, 0.07899502, 0.9843906 ],\n",
              "       [0.19045043, 0.08018857, 0.983984  ],\n",
              "       [0.19063702, 0.07987276, 0.98407346],\n",
              "       [0.19127664, 0.08043253, 0.9839311 ],\n",
              "       [0.19274002, 0.08148164, 0.98351955],\n",
              "       [0.19024748, 0.07966197, 0.98420453],\n",
              "       [0.19088939, 0.08017397, 0.98399997],\n",
              "       [0.19033036, 0.08009315, 0.9840027 ],\n",
              "       [0.19026381, 0.07978377, 0.9841288 ],\n",
              "       [0.19037044, 0.08017749, 0.983997  ],\n",
              "       [0.18927065, 0.07908854, 0.9843129 ],\n",
              "       [0.18884543, 0.07883161, 0.9843621 ],\n",
              "       [0.18974945, 0.07923561, 0.98425484],\n",
              "       [0.18916544, 0.07909971, 0.9843211 ],\n",
              "       [0.19054231, 0.07991302, 0.9840058 ],\n",
              "       [0.19085318, 0.08011091, 0.9840082 ],\n",
              "       [0.18993592, 0.07950288, 0.98424745],\n",
              "       [0.18959007, 0.0791952 , 0.9842642 ],\n",
              "       [0.19043478, 0.07968318, 0.98416805],\n",
              "       [0.19059202, 0.08006641, 0.98405313],\n",
              "       [0.19073892, 0.07990491, 0.98399127],\n",
              "       [0.19079891, 0.07994115, 0.9839769 ],\n",
              "       [0.19069669, 0.07994288, 0.98407257],\n",
              "       [0.18864441, 0.07839662, 0.98452127],\n",
              "       [0.19009984, 0.07955346, 0.984195  ],\n",
              "       [0.18926069, 0.07925862, 0.9842766 ],\n",
              "       [0.18819302, 0.07808357, 0.9845662 ],\n",
              "       [0.19065991, 0.07956463, 0.98423004],\n",
              "       [0.18883047, 0.07850438, 0.9844496 ],\n",
              "       [0.19315627, 0.08202481, 0.9833524 ],\n",
              "       [0.19134083, 0.08031762, 0.98396504],\n",
              "       [0.19220081, 0.08130121, 0.98359954],\n",
              "       [0.19038346, 0.07981181, 0.9840696 ],\n",
              "       [0.19060025, 0.07989109, 0.9840733 ],\n",
              "       [0.18991506, 0.07918373, 0.984311  ],\n",
              "       [0.19069844, 0.07971358, 0.984098  ],\n",
              "       [0.18936446, 0.07902026, 0.9843273 ],\n",
              "       [0.19037342, 0.08018252, 0.983994  ],\n",
              "       [0.19004801, 0.07936454, 0.9842746 ],\n",
              "       [0.19103655, 0.08044073, 0.98386693],\n",
              "       [0.19046855, 0.08016595, 0.9839213 ],\n",
              "       [0.1912573 , 0.08054727, 0.9838656 ],\n",
              "       [0.19071865, 0.07985133, 0.98410815],\n",
              "       [0.1907852 , 0.0800918 , 0.9840294 ],\n",
              "       [0.18984032, 0.079164  , 0.9842977 ],\n",
              "       [0.19074398, 0.08048558, 0.98389304],\n",
              "       [0.18904787, 0.07888326, 0.98437524],\n",
              "       [0.1908893 , 0.08026138, 0.98391354],\n",
              "       [0.19006851, 0.07978666, 0.9841501 ],\n",
              "       [0.19001397, 0.07942438, 0.98421067],\n",
              "       [0.1911766 , 0.08013567, 0.98392034],\n",
              "       [0.19011614, 0.07976946, 0.9840381 ],\n",
              "       [0.1900723 , 0.07964662, 0.9840634 ],\n",
              "       [0.19105804, 0.08068502, 0.98388493],\n",
              "       [0.19111732, 0.08010337, 0.9839957 ],\n",
              "       [0.19012684, 0.07941863, 0.98426485],\n",
              "       [0.19059446, 0.07975504, 0.98409784],\n",
              "       [0.18995208, 0.07922032, 0.98427176],\n",
              "       [0.18981767, 0.07948744, 0.9842614 ],\n",
              "       [0.19067034, 0.07999727, 0.983921  ],\n",
              "       [0.19045454, 0.07980618, 0.9841459 ],\n",
              "       [0.19172147, 0.08072218, 0.98380566],\n",
              "       [0.19077036, 0.07989308, 0.9840516 ],\n",
              "       [0.19108269, 0.07980856, 0.9840722 ],\n",
              "       [0.19105363, 0.0804503 , 0.98389065],\n",
              "       [0.19143885, 0.08060116, 0.98383266],\n",
              "       [0.19233298, 0.08104202, 0.9837094 ],\n",
              "       [0.18964228, 0.07974076, 0.98413146],\n",
              "       [0.18975136, 0.07979044, 0.98410594],\n",
              "       [0.19002411, 0.07953316, 0.98423314],\n",
              "       [0.18972963, 0.07974294, 0.98412323],\n",
              "       [0.19016835, 0.08008569, 0.9840437 ],\n",
              "       [0.19142652, 0.08100221, 0.9837072 ],\n",
              "       [0.19000393, 0.07937807, 0.98427814],\n",
              "       [0.19183105, 0.08078408, 0.9837733 ],\n",
              "       [0.18923461, 0.07866773, 0.98449343],\n",
              "       [0.19106862, 0.08011973, 0.9839275 ],\n",
              "       [0.18957895, 0.07906863, 0.98437595],\n",
              "       [0.191679  , 0.08091739, 0.983736  ],\n",
              "       [0.1909818 , 0.08056709, 0.98383397],\n",
              "       [0.19080302, 0.079916  , 0.9841249 ],\n",
              "       [0.1912654 , 0.08056539, 0.98385036],\n",
              "       [0.19004685, 0.07973605, 0.98418367],\n",
              "       [0.1903283 , 0.07971114, 0.9841596 ],\n",
              "       [0.19014254, 0.07929146, 0.984301  ],\n",
              "       [0.19282517, 0.08186474, 0.9835003 ],\n",
              "       [0.19216603, 0.08134365, 0.9835835 ],\n",
              "       [0.19200644, 0.08108464, 0.9836333 ],\n",
              "       [0.19189614, 0.08091751, 0.98374   ],\n",
              "       [0.19237691, 0.08124432, 0.98374104],\n",
              "       [0.18911222, 0.07886153, 0.98442435],\n",
              "       [0.19309077, 0.08203128, 0.9834163 ],\n",
              "       [0.19041452, 0.08030197, 0.98389626],\n",
              "       [0.19144765, 0.08080322, 0.983701  ],\n",
              "       [0.19043857, 0.08006227, 0.98398435],\n",
              "       [0.1907984 , 0.08015367, 0.98397416],\n",
              "       [0.1892843 , 0.07917872, 0.9842983 ],\n",
              "       [0.1915966 , 0.08112863, 0.9837199 ],\n",
              "       [0.19153935, 0.08045712, 0.9839338 ],\n",
              "       [0.19140497, 0.08057633, 0.98380184],\n",
              "       [0.19042864, 0.08009812, 0.98399574],\n",
              "       [0.19145712, 0.08050573, 0.9838548 ],\n",
              "       [0.19158837, 0.08066681, 0.9837816 ],\n",
              "       [0.19315606, 0.08206981, 0.9833957 ],\n",
              "       [0.18917346, 0.07893202, 0.9843824 ],\n",
              "       [0.19093272, 0.07977635, 0.9841182 ],\n",
              "       [0.1902599 , 0.07962462, 0.98417795],\n",
              "       [0.18957001, 0.07910034, 0.98436147],\n",
              "       [0.19039932, 0.0796065 , 0.98414063],\n",
              "       [0.19029942, 0.07984322, 0.98405325],\n",
              "       [0.19111037, 0.08032525, 0.9839468 ],\n",
              "       [0.190806  , 0.08031142, 0.9839434 ],\n",
              "       [0.190727  , 0.08011249, 0.9839387 ],\n",
              "       [0.19051588, 0.08000866, 0.9840349 ],\n",
              "       [0.19081533, 0.08031106, 0.98393893],\n",
              "       [0.19163626, 0.08079219, 0.98378325],\n",
              "       [0.19143957, 0.08081639, 0.98384225],\n",
              "       [0.19139269, 0.08078989, 0.9838513 ],\n",
              "       [0.19025922, 0.07956141, 0.9842115 ],\n",
              "       [0.19097382, 0.08035776, 0.9838775 ],\n",
              "       [0.1902155 , 0.07925105, 0.98424417],\n",
              "       [0.19034612, 0.07982102, 0.9840586 ],\n",
              "       [0.1915459 , 0.08045498, 0.9839519 ],\n",
              "       [0.1909686 , 0.08036014, 0.98387575],\n",
              "       [0.18832698, 0.07827803, 0.9845965 ],\n",
              "       [0.19000724, 0.07933962, 0.9843379 ],\n",
              "       [0.19009316, 0.07956523, 0.9841286 ],\n",
              "       [0.19016707, 0.07979226, 0.98415184],\n",
              "       [0.19029114, 0.07956949, 0.98419833],\n",
              "       [0.19182572, 0.08091149, 0.98377585],\n",
              "       [0.1904316 , 0.07962638, 0.9842277 ],\n",
              "       [0.19023278, 0.07994014, 0.9840829 ],\n",
              "       [0.19019777, 0.07997966, 0.98407954],\n",
              "       [0.19103006, 0.08035889, 0.9839318 ],\n",
              "       [0.19204485, 0.08094618, 0.983776  ],\n",
              "       [0.19052637, 0.08000734, 0.9840584 ],\n",
              "       [0.19149932, 0.08063951, 0.9838451 ],\n",
              "       [0.19101888, 0.08003843, 0.98400116],\n",
              "       [0.19192785, 0.08104149, 0.98368454],\n",
              "       [0.19016343, 0.07947811, 0.98426545],\n",
              "       [0.19042331, 0.08003205, 0.9840616 ],\n",
              "       [0.19044274, 0.07991803, 0.9839939 ],\n",
              "       [0.18996727, 0.07969031, 0.98415893],\n",
              "       [0.19015732, 0.0794194 , 0.9841862 ],\n",
              "       [0.19171107, 0.08079037, 0.98384887],\n",
              "       [0.19274288, 0.08161283, 0.9834205 ],\n",
              "       [0.19058347, 0.07969233, 0.9841302 ],\n",
              "       [0.18964249, 0.07970005, 0.9841973 ],\n",
              "       [0.18973911, 0.07951376, 0.98425823],\n",
              "       [0.18992811, 0.07922205, 0.9843849 ],\n",
              "       [0.19110507, 0.08028242, 0.9839729 ],\n",
              "       [0.19109279, 0.0802885 , 0.9839721 ],\n",
              "       [0.19263843, 0.0814479 , 0.9836595 ],\n",
              "       [0.19213027, 0.08134344, 0.9835818 ],\n",
              "       [0.19064936, 0.08017275, 0.9840041 ],\n",
              "       [0.18989784, 0.07938123, 0.9842143 ],\n",
              "       [0.19089708, 0.07997304, 0.98396873],\n",
              "       [0.18940097, 0.07869431, 0.98448193],\n",
              "       [0.18980914, 0.07928151, 0.9842235 ],\n",
              "       [0.190454  , 0.08007947, 0.9840518 ],\n",
              "       [0.19083029, 0.08002648, 0.98405755],\n",
              "       [0.18987796, 0.07939875, 0.9841678 ],\n",
              "       [0.19066256, 0.08008143, 0.984101  ],\n",
              "       [0.19137046, 0.08030835, 0.98388493],\n",
              "       [0.19061404, 0.07952729, 0.9842397 ],\n",
              "       [0.1919091 , 0.08091828, 0.98369634],\n",
              "       [0.19064495, 0.08015054, 0.98402417],\n",
              "       [0.19162917, 0.08074698, 0.9837464 ],\n",
              "       [0.1909259 , 0.080046  , 0.983984  ],\n",
              "       [0.19061804, 0.0796845 , 0.9842182 ],\n",
              "       [0.18929112, 0.07885239, 0.9843737 ],\n",
              "       [0.19053254, 0.07990277, 0.9840658 ],\n",
              "       [0.19056317, 0.07955652, 0.98421514]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HtE6nacc7BKY"
      },
      "cell_type": "markdown",
      "source": [
        "### Accuracy with Simple RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ua8S53Ne7BKZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8d2b733b-32b5-42f8-d01c-7689999e879c",
        "id": "lIIM0X8q7BKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "cell_type": "code",
      "source": [
        "test_sequences_matrix1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-21701e4890e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sequences_matrix1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sequences_matrix1' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6oPzRYaZ7BKp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1_predict = modelSimple1.predict_classes(test_sequences_matrix)\n",
        "y2_predict = modelSimple2.predict_classes(test_sequences_matrix)\n",
        "y3_predict = modelSimple3.predict_classes(test_sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7f66dd90-77f5-47fd-84fa-bf97fb83c1b7",
        "id": "-OaEsop77BKt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3578
        }
      },
      "cell_type": "code",
      "source": [
        "y2_predict"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NK-93Y5E7BKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_pred)):\n",
        "  for j in range(len(Y_pred[i])):\n",
        "    if j == 0:\n",
        "      Y_pred[i][j] = y1_predict[i]\n",
        "    elif j == 1:\n",
        "      Y_pred[i][j] = y2_predict[i]\n",
        "    elif j == 2:\n",
        "      Y_pred[i][j] = y3_predict[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a2569e69-1f5b-4d19-d1f3-781fc0d7aa64",
        "id": "BnlN9ADb7BK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3377
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred[:200]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dr0JruRU7BK_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_real = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_real)):\n",
        "  for j in range(len(Y_real[i])):\n",
        "    if j == 0:\n",
        "      Y_real[i][j] = Y1_test[i]\n",
        "    elif j == 1:\n",
        "      Y_real[i][j] = Y2_test[i]\n",
        "    elif j == 2:\n",
        "      Y_real[i][j] = Y3_test[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "420d180a-d310-4eb8-c6e1-37db41244c51",
        "id": "_XRHNOB67BLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "Y_real[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e319125a-e9cf-4da1-879a-d7ce2e9cc895",
        "id": "8x8J-EHq7BLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "hamming_loss(Y_real, Y_pred)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1069182389937107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "wmleQm_I6qIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Accuracy with LSTM RNN"
      ]
    },
    {
      "metadata": {
        "id": "aPJRMXuH1pAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkyb5aAR2Fq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1_predict = modelLSTM1.predict_classes(test_sequences_matrix)\n",
        "y2_predict = modelLSTM2.predict_classes(test_sequences_matrix)\n",
        "y3_predict = modelLSTM3.predict_classes(test_sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nv3SHnIK7M7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_pred)):\n",
        "  for j in range(len(Y_pred[i])):\n",
        "    if j == 0:\n",
        "      Y_pred[i][j] = y1_predict[i]\n",
        "    elif j == 1:\n",
        "      Y_pred[i][j] = y2_predict[i]\n",
        "    elif j == 2:\n",
        "      Y_pred[i][j] = y3_predict[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RLXiQzJiENR",
        "colab_type": "code",
        "outputId": "6b617718-71e9-4f1c-b06f-6a83ae1afacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3377
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred[:200]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [1., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "metadata": {
        "id": "xZN-wJEi_VhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_real = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_real)):\n",
        "  for j in range(len(Y_real[i])):\n",
        "    if j == 0:\n",
        "      Y_real[i][j] = Y1_test[i]\n",
        "    elif j == 1:\n",
        "      Y_real[i][j] = Y2_test[i]\n",
        "    elif j == 2:\n",
        "      Y_real[i][j] = Y3_test[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CM4jyHsW-pWO",
        "colab_type": "code",
        "outputId": "4ec49878-8283-4a77-91b0-268e86c017d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "hamming_loss(Y_real, Y_pred)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0880503144654088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "82n7jSe2AfGM"
      },
      "cell_type": "markdown",
      "source": [
        "### Accuracy with GRU RNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pdOz2kKhAfGN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2lkUDoIBAfGb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1_predict = modelGRU1.predict_classes(test_sequences_matrix)\n",
        "y2_predict = modelGRU2.predict_classes(test_sequences_matrix)\n",
        "y3_predict = modelGRU3.predict_classes(test_sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ckMGcP8aAfGr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_pred)):\n",
        "  for j in range(len(Y_pred[i])):\n",
        "    if j == 0:\n",
        "      Y_pred[i][j] = y1_predict[i]\n",
        "    elif j == 1:\n",
        "      Y_pred[i][j] = y2_predict[i]\n",
        "    elif j == 2:\n",
        "      Y_pred[i][j] = y3_predict[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_b2d3gynAfGx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_real = np.zeros((len(y3_predict),3))\n",
        "for i in range(len(Y_real)):\n",
        "  for j in range(len(Y_real[i])):\n",
        "    if j == 0:\n",
        "      Y_real[i][j] = Y1_test[i]\n",
        "    elif j == 1:\n",
        "      Y_real[i][j] = Y2_test[i]\n",
        "    elif j == 2:\n",
        "      Y_real[i][j] = Y3_test[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a46a4a0d-a073-4582-8334-c4dce11d4930",
        "id": "68oQEnA3AfG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "hamming_loss(Y_real, Y_pred)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09905660377358491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    }
  ]
}